{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Semi-supervised Learning with Gradient Descent and NumPy's `linalg.solve`\n",
    "\n",
    "In this notebook, we consider the semi-supervised learning problem given in HW1. \n",
    "\n",
    "Recall that our task is to classify unlabelled data points given a small number of labelled ones. Importatnly, our objective is a quadratic function.\n",
    "\n",
    "The goal is therefore to minimize the following objective function:\n",
    "\n",
    "$$\\min_{y \\in \\mathbb{R}^n} \\frac{1}{2}y^THy + y^Tg$$\n",
    "\n",
    "We'll implement and compare two methods to solve this problem:\n",
    "\n",
    "1. Gradient Descent.\n",
    "2. Direct solve using `numpy.linalg.solve`.\n",
    "\n",
    "We will visualize the results, showing how the model clusters the unlabelled data, and compare the performance of the two methods for different problem sizes.\n",
    "\n",
    "There are two incomplete functions left #TODO:\n",
    "\n",
    "1. `gradient_descent`: Implement the gradient descent method in the utilities.py module.\n",
    "2. `compute_Hessian_Gradient`: Compute the Hessian and gradient of the objective function in the model.py module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from model import *\n",
    "from utilities import *\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualizing the Solution\n",
    "\n",
    "Let's visualize the clusters formed by the solution found by `numpy.linalg.solve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_solution(num_samples=400, num_labelled=40, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualizing Gradient Descent Convergence\n",
    "\n",
    "Next, let's visualize the convergence of the Gradient Descent method. We plot the objective function value and the classification accuracy as the method iterates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gradient_descent_convergence(num_samples=500, num_labelled=50, gamma=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Running and Comparing Solvers\n",
    "\n",
    "Finally, we will run both solvers and compare their performance in terms of time taken for execution for different cluster sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compare_solvers(vec_num_samples = np.arange(1000, 5001, 500),\n",
    "                    vec_num_labelled = np.arange(100, 501, 50), gamma=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}